# Human Behavioral Patterns Dataset Exploration and Analysis

Welcome to the Human Behavioral Patterns Dataset Exploration and Analysis project! This repository contains a comprehensive examination of human and AI performance across various experiments and conditions, aiming to uncover insights into human-AI interaction, performance differences, and potential synergies in decision-making tasks.

## Dataset Overview

The dataset comprises behavioral data from multiple experiments, capturing key features such as:

- Experiment identifiers (Paper_ID, Exp_ID, Treatment_ID)
- Performance metrics for humans, AI, and human-AI collaboration
- Number of participants and experiments
- Temporal information (Year of study)
- Statistical measures (means, standard deviations)

## Key Findings

### 1. Performance Comparison
- On average, humans outperformed AI systems in the measured tasks.
- There is significant variability in performance across experiments for both humans and AI.

### 2. Experiment Distribution
- The number of experiments per study varies widely, ranging from 5 to 1675.
- Most studies involve a moderate number of participants, with median values around 40.

### 3. Temporal Trends
- The dataset covers studies from 2020 to 2023, with a concentration in 2021-2022.

### 4. Performance Variability
- Human performance shows higher variability compared to AI performance.
- The standard deviation of human-AI collaboration suggests interesting dynamics in combined performance.

## Visualizations

The project includes histograms and scatter plots visualizing key metrics such as:

- Paper_ID and Exp_ID distributions
- Number of experiments and participants
- Performance metrics for humans, AI, and collaborative efforts

These visualizations provide a quick overview of the data's structure and highlight potential areas for deeper analysis.

By leveraging this rich dataset, we can gain valuable insights into optimizing collaborative performance and designing more effective human-AI systems.
